@book{boydConvex2023,
  title = {Convex Optimization},
  author = {Boyd, Stephen P. and Vandenberghe, Lieven},
  date = {2023},
  edition = {Version 29},
  publisher = {Cambridge University Press},
  location = {Cambridge New York Melbourne New Delhi Singapore},
  url = {https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf},
  isbn = {978-0-521-83378-3},
  langid = {english},
  pagetotal = {716},
  file = {/Users/prandi/Zotero/storage/3R2CTZJW/Boyd and Vandenberghe - 2023 - Convex optimization.pdf}
}

@misc{jentzenMathematicalIntroductionDeep2023,
  title = {Mathematical {{Introduction}} to {{Deep Learning}}: {{Methods}}, {{Implementations}}, and {{Theory}}},
  shorttitle = {Mathematical {{Introduction}} to {{Deep Learning}}},
  author = {Jentzen, Arnulf and Kuckuck, Benno and {von Wurstemberger}, Philippe},
  year = 2023,
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2310.20360},
  urldate = {2025-11-03},
  abstract = {This book aims to provide an introduction to the topic of deep learning algorithms. We review essential components of deep learning algorithms in full mathematical detail including different artificial neural network (ANN) architectures (such as fully-connected feedforward ANNs, convolutional ANNs, recurrent ANNs, residual ANNs, and ANNs with batch normalization) and different optimization algorithms (such as the basic stochastic gradient descent (SGD) method, accelerated methods, and adaptive methods). We also cover several theoretical aspects of deep learning algorithms such as approximation capacities of ANNs (including a calculus for ANNs), optimization theory (including Kurdyka-\L ojasiewicz inequalities), and generalization errors. In the last part of the book some deep learning approximation methods for PDEs are reviewed including physics-informed neural networks (PINNs) and deep Galerkin methods. We hope that this book will be useful for students and scientists who do not yet have any background in deep learning at all and would like to gain a solid foundation as well as for practitioners who would like to obtain a firmer mathematical understanding of the objects and methods considered in deep learning.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {68T07,Artificial Intelligence (cs.AI),FOS: Computer and information sciences,FOS: Mathematics,Machine Learning (cs.LG),Machine Learning (stat.ML),Numerical Analysis (math.NA),Probability (math.PR)},
  file = {C:\Users\dario\Zotero\storage\X2QDYE8I\Jentzen et al. - 2023 - Mathematical Introduction to Deep Learning Methods, Implementations, and Theory.pdf}
}


@book{coronControl2009,
  title = {Control and Nonlinearity},
  author = {Coron, Jean-Michel},
  date = {2009},
  url = {http://books.google.com/books?hl=en&lr=&id=R5h9X2yYKqkC&oi=fnd&pg=PR9&dq=Control+and+Nonlinearity&ots=H6d6e0g-0f&sig=ERNsE53DETC5HWEAAO988sIta9c},
  isbn = {978-0-8218-3668-2},
  file = {/Users/prandi/Zotero/storage/TD83IVAQ/Coron - 2009 - Control and nonlinearity.pdf}
}

@book{facchineiFinitedimensional2003,
  title = {Finite-Dimensional Variational Inequalities and Complementarity Problems},
  author = {Facchinei, Francisco and Pang, Jong-Shi},
  date = {2003},
  series = {Springer Series in Operations Research},
  publisher = {Springer},
  location = {New York},
  isbn = {978-0-387-95580-3 978-0-387-95581-0},
  langid = {english},
  pagetotal = {2},
  keywords = {Linear complementarity problem,Variational inequalities (Mathematics)},
  file = {/Users/prandi/Zotero/storage/T4Z3FEBP/Facchinei and Pang - 2003 - Finite-dimensional variational inequalities and complementarity problems.pdf}
}

@book{facchineiFinitedimensional2003a,
  title = {Finite-Dimensional Variational Inequalities and Complementarity Problems},
  author = {Facchinei, Francisco and Pang, Jong-Shi},
  date = {2003},
  series = {Springer Series in Operations Research},
  publisher = {Springer},
  location = {New York},
  isbn = {978-0-387-95580-3 978-0-387-95581-0},
  langid = {english},
  pagetotal = {2},
  keywords = {Linear complementarity problem,Variational inequalities (Mathematics)},
  file = {/Users/prandi/Zotero/storage/TV2WDQGV/Facchinei and Pang - 2003 - Finite-dimensional variational inequalities and complementarity problems.pdf}
}

@online{fawziLecture,
  title = {Lecture Notes for {{Topics}} in {{Convex Optimisation}}},
  author = {Fawzi, Hamza},
  url = {https://www.damtp.cam.ac.uk/user/hf323/L22-III-OPT/}
}

@unpublished{fornasierFoundations,
  title = {Foundations of {{Data Analysis}}},
  author = {Fornasier, Massimo}
}

@book{jurdjevicGeometric1997,
  title = {Geometric Control Theory},
  author = {Jurdjevic, Velimir},
  date = {1997},
  series = {Cambridge Studies in Advanced Mathematics},
  number = {51},
  publisher = {Cambridge university press},
  location = {Cambridge},
  isbn = {978-0-521-49502-8},
  langid = {english},
  file = {/Users/prandi/Zotero/storage/QRTX8RNS/Velimir Jurdjevic Geometric Control Theory  1996.djvu}
}

@book{rockafellarConvex2015,
  title = {Convex {{Analysis}}},
  author = {Rockafellar, Ralph Tyrell},
  date = {2015},
  series = {Princeton {{Landmarks}} in {{Mathematics}} and {{Physics}}},
  publisher = {Princeton University Press},
  location = {Princeton},
  abstract = {Available for the first time in paperback, R. Tyrrell Rockafellar's classic study presents readers with a coherent branch of nonlinear mathematical analysis that is especially suited to the study of optimization problems. Rockafellar's theory differs from classical analysis in that differentiability assumptions are replaced by convexity assumptions. The topics treated in this volume include: systems of inequalities, the minimum or maximum of a convex function over a convex set, Lagrange multipliers, minimax theorems and duality, as well as basic results about the structure of convex sets and},
  isbn = {978-0-691-01586-6},
  langid = {english},
  pagetotal = {470}
}

@article{royerLecture,
  title = {Lecture Notes on Stochastic Gradient Methods},
  author = {Royer, Clement W},
  url = {https://www.lamsade.dauphine.fr/~croyer/ensdocs/SG/LectureNotesOML-SG.pdf},
  langid = {english},
  file = {/Users/prandi/Zotero/storage/6N2662EU/Royer - Lecture notes on stochastic gradient methods.pdf}
}

@book{trelatControl2024,
  title = {Control in {{Finite}} and {{Infinite Dimension}}},
  author = {Trélat, Emmanuel},
  date = {2024},
  series = {{{SpringerBriefs}} on {{PDEs}} and {{Data Science}}},
  publisher = {Springer Nature Singapore},
  location = {Singapore},
  doi = {10.1007/978-981-97-5948-4},
  url = {https://link.springer.com/10.1007/978-981-97-5948-4},
  urldate = {2025-10-06},
  isbn = {978-981-97-5947-7 978-981-97-5948-4},
  langid = {english},
  file = {/Users/prandi/Zotero/storage/RHLB3KJK/Trélat - 2024 - Control in Finite and Infinite Dimension.pdf}
}

@book{trelatControle2005,
  title = {Contrôle optimal: théorie \& applications},
  shorttitle = {Contrôle optimal},
  author = {Trélat, Emmanuel},
  date = {2005},
  publisher = {Vuibert},
  location = {Paris},
  isbn = {978-2-7117-7175-2},
  langid = {french},
  annotation = {OCLC: 77534126},
  file = {/Users/prandi/Zotero/storage/7P9FVR2I/Trélat - 2005 - Contrôle optimal théorie & applications.pdf}
}
